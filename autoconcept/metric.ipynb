{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import load_experiment\n",
    "\n",
    "PATH_PREFIX = \"/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/autoconcept\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching configuration...\n",
      "Loading datamodule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/danis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             filename  \\\n",
      "0  Black_Footed_Albatross_0046_18.jpg   \n",
      "1  Black_Footed_Albatross_0009_34.jpg   \n",
      "2  Black_Footed_Albatross_0002_55.jpg   \n",
      "3  Black_Footed_Albatross_0074_59.jpg   \n",
      "4  Black_Footed_Albatross_0014_89.jpg   \n",
      "\n",
      "                                     source_captions  \\\n",
      "0  ['closeup bin food include broccoli bread', 'm...   \n",
      "1  ['giraffe eating food top tree', 'giraffe stan...   \n",
      "2  ['flower vase sitting porch stand', 'white vas...   \n",
      "3  ['zebra grazing lush green grass field', 'zebr...   \n",
      "4  ['woman swim suit holding parasol sunny day', ...   \n",
      "\n",
      "                                mask_source_captions  \\\n",
      "0  ['coco', 'coco', 'coco', 'coco', 'coco', 'cub'...   \n",
      "1  ['coco', 'coco', 'coco', 'coco', 'coco', 'cub'...   \n",
      "2  ['coco', 'coco', 'coco', 'coco', 'coco', 'cub'...   \n",
      "3  ['coco', 'coco', 'coco', 'coco', 'coco', 'cub'...   \n",
      "4  ['coco', 'coco', 'coco', 'coco', 'coco', 'cub'...   \n",
      "\n",
      "                                          attributes  \n",
      "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
      "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11788/11788 [00:06<00:00, 1799.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  373\n",
      "Index for <pad>: [0]\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_task' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_task'])`.\n",
      "  rank_zero_warn(\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_tie' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_tie'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "experiment_path = \"outputs/2023-05-28/09-21-34\"\n",
    "\n",
    "dm, model = load_experiment(os.path.join(PATH_PREFIX, experiment_path))\n",
    "train_loader = dm.train_dataloader()\n",
    "train_set = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[ 1.1700,  1.1700,  1.1700,  ..., -0.4739, -0.6281, -0.6965],\n",
       "          [ 1.1700,  1.1700,  1.1700,  ..., -0.3541, -0.4911, -0.5596],\n",
       "          [ 1.1700,  1.1700,  1.1529,  ..., -0.1828, -0.3027, -0.3541],\n",
       "          ...,\n",
       "          [ 1.8722,  1.8722,  1.8722,  ...,  1.8722,  1.8722,  1.8722],\n",
       "          [ 0.8961,  0.8961,  0.8961,  ...,  0.8961,  0.8961,  0.8961],\n",
       "          [ 0.2453,  0.2453,  0.2453,  ...,  0.2453,  0.2453,  0.2453]],\n",
       " \n",
       "         [[ 1.2206,  1.2206,  1.2206,  ..., -0.6001, -0.7577, -0.8277],\n",
       "          [ 1.2206,  1.2206,  1.2206,  ..., -0.5126, -0.6527, -0.7227],\n",
       "          [ 1.2206,  1.2206,  1.2031,  ..., -0.3725, -0.4951, -0.5476],\n",
       "          ...,\n",
       "          [ 2.0434,  2.0434,  2.0434,  ...,  2.0434,  2.0434,  2.0434],\n",
       "          [ 1.0455,  1.0455,  1.0455,  ...,  1.0455,  1.0455,  1.0455],\n",
       "          [ 0.3803,  0.3803,  0.3803,  ...,  0.3803,  0.3803,  0.3803]],\n",
       " \n",
       "         [[ 1.7685,  1.7685,  1.7685,  ..., -0.3055, -0.4624, -0.5321],\n",
       "          [ 1.7685,  1.7685,  1.7685,  ..., -0.2532, -0.3753, -0.4450],\n",
       "          [ 1.7685,  1.7511,  1.7511,  ..., -0.1487, -0.2707, -0.3230],\n",
       "          ...,\n",
       "          [ 2.2391,  2.2391,  2.2391,  ...,  2.2566,  2.2566,  2.2566],\n",
       "          [ 1.2631,  1.2631,  1.2631,  ...,  1.2631,  1.2631,  1.2631],\n",
       "          [ 0.6008,  0.6008,  0.6008,  ...,  0.6008,  0.6008,  0.6008]]]),\n",
       " 'img_path': '/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/data/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0009_34.jpg',\n",
       " 'report': 'this bird not visibily hooked seabird beak shape this bird definitely grey wing this bird definitely grey upperparts this bird definitely grey underpart this bird definitely white underpart this bird not visibily solid breast pattern this bird definitely grey back this bird definitely notched tail this bird definitely grey upper tail this bird definitely spotted head pattern this bird definitely eyebrow head pattern this bird definitely striped head pattern this bird definitely white breast this bird definitely grey throat this bird definitely red throat this bird definitely black eye this bird definitely medium beak this bird definitely grey forehead this bird definitely red forehead this bird definitely grey under tail this bird definitely grey nape this bird definitely white belly this bird definitely roundedwings this bird definitely medium size this bird definitely perchinglike shape this bird definitely grey primary this bird definitely brown leg this bird definitely red beak this bird definitely grey crown',\n",
       " 'target_one_hot': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]),\n",
       " 'attributes': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]),\n",
       " 'class_id': 1,\n",
       " 'class_name': '001.Black_footed_Albatross',\n",
       " 'source_captions': ['this bird not visibily hooked seabird beak shape',\n",
       "  'this bird definitely grey wing',\n",
       "  'this bird definitely grey upperparts',\n",
       "  'this bird definitely grey underpart',\n",
       "  'this bird definitely white underpart',\n",
       "  'this bird not visibily solid breast pattern',\n",
       "  'this bird definitely grey back',\n",
       "  'this bird definitely notched tail',\n",
       "  'this bird definitely grey upper tail',\n",
       "  'this bird definitely spotted head pattern',\n",
       "  'this bird definitely eyebrow head pattern',\n",
       "  'this bird definitely striped head pattern',\n",
       "  'this bird definitely white breast',\n",
       "  'this bird definitely grey throat',\n",
       "  'this bird definitely red throat',\n",
       "  'this bird definitely black eye',\n",
       "  'this bird definitely medium beak',\n",
       "  'this bird definitely grey forehead',\n",
       "  'this bird definitely red forehead',\n",
       "  'this bird definitely grey under tail',\n",
       "  'this bird definitely grey nape',\n",
       "  'this bird definitely white belly',\n",
       "  'this bird definitely roundedwings',\n",
       "  'this bird definitely medium size',\n",
       "  'this bird definitely perchinglike shape',\n",
       "  'this bird definitely grey primary',\n",
       "  'this bird definitely brown leg',\n",
       "  'this bird definitely red beak',\n",
       "  'this bird definitely grey crown'],\n",
       " 'mask_source_captions': ['cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub',\n",
       "  'cub'],\n",
       " 'target': tensor(0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes dataset\n",
    "# [red, green, blue, square, triangle, circle, ... each for class]\n",
    "\n",
    "attribute_mapping = {\n",
    "    0: [1, 0, 0, 1, 0, 0, # 1, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    1: [0, 1, 0, 1, 0, 0, # 0, 1, 0, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    2: [0, 0, 1, 1, 0, 0, # 0, 0, 1, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    3: [1, 0, 0, 0, 1, 0, # 0, 0, 0, 1, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    4: [0, 1, 0, 0, 1, 0, # 0, 0, 0, 0, 1, 0, 0, 0, 0\n",
    "        ],\n",
    "    5: [0, 0, 1, 0, 1, 0, # 0, 0, 0, 0, 0, 1, 0, 0, 0\n",
    "        ],\n",
    "    6: [1, 0, 0, 0, 0, 1, # 0, 0, 0, 0, 0, 0, 1, 0, 0\n",
    "        ],\n",
    "    7: [0, 1, 0, 0, 0, 1, # 0, 0, 0, 0, 0, 0, 0, 1, 0\n",
    "        ],\n",
    "    8: [0, 0, 1, 0, 0, 1, # 0, 0, 0, 0, 0, 0, 0, 0, 1\n",
    "        ],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICLR 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(loader, model):\n",
    "    # y_train = z\n",
    "    # X_train = c\n",
    "\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "\n",
    "    X_train, y_train = list(), list()\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(312)] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets = batch[\"image\"].cuda(), batch[\"target\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            target = targets[sample_id].item()\n",
    "            attributes = np.array(attribute_mapping[target])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            X_train.append(features)\n",
    "            y_train.append(attributes)\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = prepare_data(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:32<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(loader, model):\n",
    "    # y_train = z\n",
    "    # X_train = c\n",
    "\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "\n",
    "    X_train, y_train = list(), list()\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(312)] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets, attributes_all = batch[\"image\"].cuda(), batch[\"target\"], batch[\"attributes\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            attributes = np.array(attributes_all[sample_id])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            X_train.append(features)\n",
    "            y_train.append(attributes)\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = prepare_data(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4795, 320), (4795,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [1:16:50<00:00, 14.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(320, 312)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z \n",
    "# n_attributes = len(attribute_mapping[0])\n",
    "n_attributes = 312\n",
    "\n",
    "R = list()\n",
    "for regressor_idx in tqdm(range(n_attributes)):\n",
    "    regressor = RandomForestRegressor(random_state=42, n_estimators=20, max_depth=10)\n",
    "    regressor.fit(X_train, y_train[:, regressor_idx])\n",
    "    regressor.predict(X_train)\n",
    "    R.append(regressor.feature_importances_)\n",
    "\n",
    "R = np.array(R).T\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01065513, 0.00023421, 0.        , ..., 0.00150469, 0.00411365,\n",
       "        0.00341284],\n",
       "       [0.00104293, 0.00028857, 0.        , ..., 0.00467915, 0.00299846,\n",
       "        0.00283151],\n",
       "       [0.        , 0.01684333, 0.        , ..., 0.00578139, 0.00548545,\n",
       "        0.00443037],\n",
       "       ...,\n",
       "       [0.        , 0.00907227, 0.00228571, ..., 0.008683  , 0.00115439,\n",
       "        0.00370512],\n",
       "       [0.        , 0.00216779, 0.        , ..., 0.00297677, 0.00657818,\n",
       "        0.0022822 ],\n",
       "       [0.00118685, 0.00330307, 0.00428127, ..., 0.00742537, 0.00288802,\n",
       "        0.00361933]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0050334 , 0.00235054, 0.00296817, ..., 0.00220805, 0.00335788,\n",
       "        0.00373513],\n",
       "       [0.00050124, 0.00154265, 0.00243333, ..., 0.00363363, 0.00257738,\n",
       "        0.00340801],\n",
       "       [0.0053127 , 0.01799806, 0.00125365, ..., 0.00480012, 0.00333179,\n",
       "        0.00360335],\n",
       "       ...,\n",
       "       [0.00149724, 0.00840936, 0.00200709, ..., 0.00659904, 0.00258421,\n",
       "        0.0026977 ],\n",
       "       [0.00196808, 0.00191371, 0.00114738, ..., 0.00224508, 0.00397609,\n",
       "        0.0028303 ],\n",
       "       [0.00330832, 0.00170234, 0.00080454, ..., 0.0060486 , 0.00260751,\n",
       "        0.00315783]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TINY = 1e-12\n",
    "\n",
    "def norm_entropy(p):\n",
    "    '''p: probabilities '''\n",
    "    n = p.shape[0]\n",
    "    return - p.dot(np.log(p + TINY) / np.log(n + TINY))\n",
    "\n",
    "def entropic_scores(r):\n",
    "    '''r: relative importances '''\n",
    "    r = np.abs(r)\n",
    "    ps = r / np.sum(r, axis=0) # 'probabilities'\n",
    "    hs = [1-norm_entropy(p) for p in ps.T]\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disentanglement 0.19307799240039877\n"
     ]
    }
   ],
   "source": [
    "disent_scores = entropic_scores(R.T)\n",
    "c_rel_importance = np.sum(R,1) / np.sum(R)\n",
    "disent_w_avg = np.sum(np.array(disent_scores) * c_rel_importance)\n",
    "print(\"disentanglement\", disent_w_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness 0.20128058402099108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26475/1556644855.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ps = r / np.sum(r, axis=0) # 'probabilities'\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "complete_scores = entropic_scores(R)\n",
    "complete_scores = [v for v in complete_scores if not math.isnan(v)]\n",
    "complete_avg = np.mean(complete_scores)\n",
    "\n",
    "print(\"completeness\", complete_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [2:03:49<00:00, 99.06s/it]  \n"
     ]
    }
   ],
   "source": [
    "def compute_purity(loader, model):\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(312)] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets, attributes_all = batch[\"image\"].cuda(), batch[\"target\"], batch[\"attributes\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            target = targets[sample_id].item()\n",
    "            attributes = np.array(attributes_all[sample_id])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            for feature_id in range(n_features):\n",
    "\n",
    "                feature = features[feature_id]\n",
    "\n",
    "                for attribute_id, attribute in enumerate(attributes):\n",
    "                    value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "                    attribute_values[feature_id][attribute_id][0] += value_on\n",
    "\n",
    "                    value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "                    attribute_values[feature_id][attribute_id][1] += value_off\n",
    "    \n",
    "    for a in attribute_values:\n",
    "        a_ = [max(p) / len(train_set) for p in a]\n",
    "        features_to_attributes.append(a_)\n",
    "    \n",
    "    return features_to_attributes\n",
    "\n",
    "f2a = compute_purity(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attribute_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m         features_to_attributes\u001b[39m.\u001b[39mappend(a_)\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m features_to_attributes\n\u001b[0;32m---> 39\u001b[0m f2a \u001b[39m=\u001b[39m compute_purity(train_loader, model, attribute_mapping)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attribute_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_purity(loader, model, attribute_mapping):\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(len(attribute_mapping[0]))] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets = batch[\"image\"].cuda(), batch[\"target\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            target = targets[sample_id].item()\n",
    "            attributes = np.array(attribute_mapping[target])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            for feature_id in range(n_features):\n",
    "\n",
    "                feature = features[feature_id]\n",
    "\n",
    "                for attribute_id, attribute in enumerate(attributes):\n",
    "                    value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "                    attribute_values[feature_id][attribute_id][0] += value_on\n",
    "\n",
    "                    value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "                    attribute_values[feature_id][attribute_id][1] += value_off\n",
    "    \n",
    "    for a in attribute_values:\n",
    "        a_ = [max(p) / len(train_set) for p in a]\n",
    "        features_to_attributes.append(a_)\n",
    "    \n",
    "    return features_to_attributes\n",
    "\n",
    "f2a = compute_purity(train_loader, model, attribute_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.5783433018127448\n"
     ]
    }
   ],
   "source": [
    "def find_best_alignment(features_to_attributes, iter_converge=20.0):\n",
    "    n_features, n_attributes = np.array(features_to_attributes).shape\n",
    "\n",
    "    features_to_attributes_ = list()\n",
    "    for feature_to_attributes in features_to_attributes:\n",
    "        feature_to_attributes_ = sorted([(idx, fa) for idx, fa in enumerate(feature_to_attributes)], key=lambda x: x[1], reverse=True)\n",
    "        features_to_attributes_.append(feature_to_attributes_)\n",
    "    \n",
    "    attributes_to_features = list(list() for _ in range(n_attributes))\n",
    "\n",
    "    for idx_feat, feature_to_attributes in enumerate(features_to_attributes_):\n",
    "        for idx_attr, score in feature_to_attributes:\n",
    "            attributes_to_features[idx_attr].append((idx_feat, score))\n",
    "    \n",
    "    attributes_to_features_ = list()\n",
    "    for attr2feature in attributes_to_features:\n",
    "        attributes_to_features_.append(sorted(attr2feature, key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    best_idx = list(None for _ in range(n_features))\n",
    "    best_scores = list(None for _ in range(n_features))\n",
    "\n",
    "    patience_left = iter_converge\n",
    "\n",
    "    while None in best_idx and patience_left > 0:\n",
    "        prev_best = [_ for _ in best_idx]\n",
    "\n",
    "        for feat_idx, f2a in enumerate(features_to_attributes_):\n",
    "            \n",
    "            if best_idx[feat_idx] is None:\n",
    "\n",
    "                for att_idx, score in f2a:\n",
    "\n",
    "                    if att_idx not in best_idx:\n",
    "                        best_idx[feat_idx] = att_idx\n",
    "                        best_scores[feat_idx] = score\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        idx_other = best_idx.index(att_idx)\n",
    "                        score_other = best_scores[idx_other]\n",
    "\n",
    "                        if score > score_other:\n",
    "                            best_idx[feat_idx] = att_idx\n",
    "                            best_scores[feat_idx] = score\n",
    "\n",
    "                            best_idx[idx_other] = None\n",
    "                            best_scores[idx_other] = None\n",
    "                            break\n",
    "        \n",
    "        if best_idx == prev_best:\n",
    "            patience_left -= 1\n",
    "        else:\n",
    "            patience_left = iter_converge\n",
    "        \n",
    "    return list(zip(best_idx, best_scores))\n",
    "\n",
    "    \n",
    "result = find_best_alignment(f2a)\n",
    "\n",
    "scores = [b for _, b in result if b is not None]\n",
    "print(\"Purity: \", np.array(scores).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Shapes dataset\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | cluster | align | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.830247` | `0.767724` | `0.465324 `| `0.481560` |  `A`  | `-`  | `outputs/2023-05-22/08-37-36` |\n",
    "| Baseline | `gumbel` |   `-`   |   `-`   |  `-`   | `0.404321`  | `0.828083` | `0.316362` | `0.276083` | `A` | `-` |  `outputs/2023-05-22/08-49-23`  |\n",
    "| Framework | `sigmoid` | `softmax`   |  `false`   |     `false`   | `0.969136`  | `0.636225`  | `0.437534` | `0.408124` | `B` | `D` | `outputs/2023-05-22/08-18-17` |  \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `false`  |   `0.848765`  |  `0.763983`    | `0.651922` | `0.611969` |   `B` |  `C`   |  `outputs/2023-05-22/08-04-48`  |  \n",
    "| Framework | `gumbel` |  `entmax`   |  `false`   |    `false`  |   `0.842593`  |  `0.748309`     | `0.742202` | `0.736384` |  `A`  |  `B`  |  `outputs/2023-05-22/09-13-40`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `true`   |    `false`  |   `0.731482`  |  `0.707190`     | `0.670618` | `0.637436` |   `A` |  `B`  |  `outputs/2023-05-22/09-38-41`  | \n",
    "| Framework | `gumbel` |  `entmax`   |  `true`   |    `false`  |   `0.586420`  |  `0.691018`     | `0.582086` | `0.564636` |  `A`  |  `B`  |  `outputs/2023-05-22/11-03-11`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `true`  |   `0.814815`  |  `0.726690`    | `0.708535` | `0.673539` |  `A` | `D` |  `outputs/2023-05-22/09-53-54`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CUB-200 \n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.805452` | `0.573071` | `0.189394`| `0.196021` | `outputs/2023-05-26/07-31-18` |\n",
    "| Baseline | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.765`  | `0.578` | `0.193078` | `0.201281` | `outputs/2023-05-28/09-21-34`  |\n",
    "| Framework | `gumbel (0.5)` |  `entmax`   |  `false`   |    `false`  |   `0.773003`  |  `0.593836`    | `0.229795` | `0.255646` |   `outputs/2023-05-27/10-34-06`  | \n",
    "| Framework | `gumbel (0.01)` |  `entmax`   |  `false`   |    `false`  |   `0.726`  |  `0.657`    | `X` | `X` |   `outputs/2023-05-27/19-41-06`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bottleneck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
