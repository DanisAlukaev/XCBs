{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import load_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching configuration...\n",
      "Loading datamodule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/danis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 2700/2700 [00:00<00:00, 9701.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of vocab:  54\n",
      "Max len of caption:  16\n",
      "Index for <pad>: [0]\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "dm, model = load_experiment(\"/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/autoconcept/outputs/2023-05-10/05-22-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()\n",
    "train_set = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [red, green, blue, square, triangle, circle]\n",
    "\n",
    "attribute_mapping = {\n",
    "    0: [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    1: [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    2: [0, 0, 1, 1, 0, 0,  0, 0, 1, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    3: [1, 0, 0, 0, 1, 0,   0, 0, 0, 1, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    4: [0, 1, 0, 0, 1, 0,   0, 0, 0, 0, 1, 0, 0, 0, 0\n",
    "        ],\n",
    "    5: [0, 0, 1, 0, 1, 0,   0, 0, 0, 0, 0, 1, 0, 0, 0\n",
    "        ],\n",
    "    6: [1, 0, 0, 0, 0, 1,   0, 0, 0, 0, 0, 0, 1, 0, 0\n",
    "        ],\n",
    "    7: [0, 1, 0, 0, 0, 1,   0, 0, 0, 0, 0, 0, 0, 1, 0\n",
    "        ],\n",
    "    8: [0, 0, 1, 0, 0, 1,   0, 0, 0, 0, 0, 0, 0, 0, 1\n",
    "        ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18115692, 0.32691154, 0.95352095, 0.11858784, 0.25531936,\n",
       "       0.31551293, 0.04973926, 0.0362053 , 0.8385405 , 0.1468492 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_set[50]\n",
    "image = sample[\"image\"]\n",
    "\n",
    "image = image.unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "# model.main.inference(image)[1].cpu().detach().numpy()[0]\n",
    "model(image)[\"concept_probs\"].cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1845/1845 [00:33<00:00, 54.52it/s]\n",
      "100%|██████████| 1845/1845 [00:33<00:00, 55.03it/s]\n",
      "100%|██████████| 1845/1845 [00:33<00:00, 54.86it/s]\n",
      "100%|██████████| 1845/1845 [00:33<00:00, 55.08it/s]\n",
      "100%|██████████| 1845/1845 [00:33<00:00, 54.90it/s]\n",
      "100%|██████████| 1845/1845 [00:37<00:00, 48.57it/s]\n",
      "100%|██████████| 1845/1845 [00:35<00:00, 51.83it/s]\n",
      "100%|██████████| 1845/1845 [00:35<00:00, 52.22it/s]\n",
      "100%|██████████| 1845/1845 [00:36<00:00, 50.23it/s]\n",
      "100%|██████████| 1845/1845 [00:36<00:00, 50.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7329807396802224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "\n",
    "for feature_id in range(10):\n",
    "\n",
    "    attribute_values = [[0, 0] for _ in range(len(attribute_mapping[0]))]\n",
    "\n",
    "    for i in tqdm(range(len(train_set))):\n",
    "        sample = train_set[i]\n",
    "        \n",
    "        idx = sample[\"target\"].item()\n",
    "        attributes = np.array(attribute_mapping[idx])\n",
    "\n",
    "        image = sample[\"image\"]\n",
    "        image = image.unsqueeze(0).cuda()\n",
    "\n",
    "        # feature = model.main.inference(image)[1].cpu().detach().numpy()[0][feature_id]\n",
    "        feature = model(image)[\"concept_probs\"].cpu().detach().numpy()[0][feature_id]\n",
    "\n",
    "        for attr_id, attribute in enumerate(attributes):\n",
    "            value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "            attribute_values[attr_id][0] += value_on\n",
    "\n",
    "            value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "            attribute_values[attr_id][1] += value_off\n",
    "    \n",
    "    attribute_values_max = [max(p) for p in attribute_values]\n",
    "    attribute_values_max = max(attribute_values_max)\n",
    "    score = attribute_values_max / len(train_set)\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "metric = np.array(scores).mean()\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline: 0.7481238945043126 / 0.8002787673469156 / \n",
    "\n",
    "Our framework: 0.733698356318566 / 0.733698356318566 / 0.77456 (w/o textual, anneal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7387194722921141,\n",
       " 0.7676965905446812,\n",
       " 0.7516099136302545,\n",
       " 0.673259667055757,\n",
       " 0.7868074841999264,\n",
       " 0.6593413541048039,\n",
       " 0.6775105591086029,\n",
       " 0.6476065091748386,\n",
       " 0.8292717628463658,\n",
       " 0.5818808208090988]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7387194722921141,\n",
       " 0.7676965905446812,\n",
       " 0.7516099136302545,\n",
       " 0.673259667055757,\n",
       " 0.7868074841999264,\n",
       " 0.6593413541048039,\n",
       " 0.6775105591086029,\n",
       " 0.6476065091748386,\n",
       " 0.8292717628463658,\n",
       " 0.5818808208090988]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores # framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bottleneck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
