{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import load_experiment\n",
    "\n",
    "PATH_PREFIX = \"/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/autoconcept\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching configuration...\n",
      "Loading datamodule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/danis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 15000/15000 [00:03<00:00, 3995.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of vocab:  8651\n",
      "Max len of caption:  378\n",
      "Index for <pad>: [0]\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_task' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_task'])`.\n",
      "  rank_zero_warn(\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_tie' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_tie'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "experiment_path = \"outputs/2023-06-01/13-18-08\"\n",
    "\n",
    "dm, model = load_experiment(os.path.join(PATH_PREFIX, experiment_path))\n",
    "train_loader = dm.train_dataloader()\n",
    "train_set = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       " \n",
       "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       " \n",
       "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n",
       " 'img_path': '/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/data/mimic-cxr/images/90b54631-adb0bc5f-8c2a14fa-8c64f539-48caa35a.jpg',\n",
       " 'report': 'final report chest radiograph performed comparison none clinical history stroke pneumonia leaning right dizziness finding ap upright lateral view chest provided heart enlarged allowing technique lung volume low bronchovascular crowding obscuring lung base upper lung appear well aerated no pneumothorax seen bony structure intact impression limited exam cardiomegaly lower lung bronchovascular opacity setting low lung volume if strong clinical concern pneumonia recommend repeat more optimal inspiratory effort',\n",
       " 'target_one_hot': tensor(1),\n",
       " 'attributes': tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'target': tensor(1)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[5848]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes dataset\n",
    "# [red, green, blue, square, triangle, circle, ... each for class]\n",
    "\n",
    "attribute_mapping = {\n",
    "    0: [1, 0, 0, 1, 0, 0, # 1, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    1: [0, 1, 0, 1, 0, 0, # 0, 1, 0, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    2: [0, 0, 1, 1, 0, 0, # 0, 0, 1, 0, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    3: [1, 0, 0, 0, 1, 0, # 0, 0, 0, 1, 0, 0, 0, 0, 0\n",
    "        ],\n",
    "    4: [0, 1, 0, 0, 1, 0, # 0, 0, 0, 0, 1, 0, 0, 0, 0\n",
    "        ],\n",
    "    5: [0, 0, 1, 0, 1, 0, # 0, 0, 0, 0, 0, 1, 0, 0, 0\n",
    "        ],\n",
    "    6: [1, 0, 0, 0, 0, 1, # 0, 0, 0, 0, 0, 0, 1, 0, 0\n",
    "        ],\n",
    "    7: [0, 1, 0, 0, 0, 1, # 0, 0, 0, 0, 0, 0, 0, 1, 0\n",
    "        ],\n",
    "    8: [0, 0, 1, 0, 0, 1, # 0, 0, 0, 0, 0, 0, 0, 0, 1\n",
    "        ],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICLR 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(loader, model):\n",
    "    # y_train = z\n",
    "    # X_train = c\n",
    "\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "\n",
    "    X_train, y_train = list(), list()\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(312)] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets = batch[\"image\"].cuda(), batch[\"target\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            target = targets[sample_id].item()\n",
    "            attributes = np.array(attribute_mapping[target])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            X_train.append(features)\n",
    "            y_train.append(attributes)\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = prepare_data(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [01:02<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(loader, model):\n",
    "    # y_train = z\n",
    "    # X_train = c\n",
    "\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "\n",
    "    X_train, y_train = list(), list()\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(312)] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets, attributes_all = batch[\"image\"].cuda(), batch[\"target\"], batch[\"attributes\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            attributes = np.array(attributes_all[sample_id])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            X_train.append(features)\n",
    "            y_train.append(attributes)\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = prepare_data(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10500, 16), (10500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [02:51<00:00, 12.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z \n",
    "# n_attributes = len(attribute_mapping[0])\n",
    "n_attributes = 14\n",
    "\n",
    "R = list()\n",
    "for regressor_idx in tqdm(range(n_attributes)):\n",
    "    regressor = RandomForestRegressor(random_state=42, \n",
    "                                      # n_estimators=20, max_depth=10\n",
    "                                      )\n",
    "    regressor.fit(X_train, y_train[:, regressor_idx])\n",
    "    regressor.predict(X_train)\n",
    "    R.append(regressor.feature_importances_)\n",
    "\n",
    "R = np.array(R).T\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07200525, 0.05454302, 0.04597642, 0.06446222, 0.03866391,\n",
       "        0.08985318, 0.09213552, 0.11334525, 0.05497458, 0.03615143,\n",
       "        0.11715389, 0.07652172, 0.08036046, 0.03418634],\n",
       "       [0.05510592, 0.04646787, 0.04435685, 0.04666972, 0.04509134,\n",
       "        0.06740969, 0.09867668, 0.05144792, 0.03701053, 0.03059866,\n",
       "        0.07063894, 0.07363651, 0.05795716, 0.02495355],\n",
       "       [0.05487397, 0.10201131, 0.03264286, 0.06043465, 0.07280723,\n",
       "        0.04497903, 0.02695523, 0.03629714, 0.05961006, 0.14721499,\n",
       "        0.07115423, 0.04651815, 0.06597503, 0.02472615],\n",
       "       [0.03302828, 0.09682789, 0.0515818 , 0.03835   , 0.06807026,\n",
       "        0.03638972, 0.04821815, 0.02289699, 0.05058192, 0.08542952,\n",
       "        0.03829264, 0.04978884, 0.05314857, 0.02672816],\n",
       "       [0.05052749, 0.04947342, 0.04427887, 0.04214611, 0.03933383,\n",
       "        0.07509862, 0.07808738, 0.07561675, 0.03439476, 0.03484511,\n",
       "        0.08530105, 0.06647298, 0.05752562, 0.02439193],\n",
       "       [0.06120459, 0.06879334, 0.03791896, 0.0990672 , 0.09868873,\n",
       "        0.05528422, 0.04793314, 0.03030376, 0.16963646, 0.1133118 ,\n",
       "        0.05030489, 0.05483228, 0.07661797, 0.03004067],\n",
       "       [0.07309052, 0.06179358, 0.08577725, 0.09345806, 0.05227106,\n",
       "        0.07513249, 0.06691825, 0.06190035, 0.07827609, 0.03990574,\n",
       "        0.06798447, 0.04251784, 0.06799812, 0.13647402],\n",
       "       [0.1333796 , 0.06137644, 0.05893605, 0.09737946, 0.06611947,\n",
       "        0.08695005, 0.0813276 , 0.09188739, 0.05845076, 0.04628969,\n",
       "        0.06594798, 0.04895643, 0.06203513, 0.37524584],\n",
       "       [0.0454776 , 0.07414925, 0.05916809, 0.06712021, 0.10793756,\n",
       "        0.05958235, 0.05887478, 0.03994445, 0.06367062, 0.05824282,\n",
       "        0.03806669, 0.03639789, 0.06484134, 0.06342159],\n",
       "       [0.11445473, 0.05656223, 0.04946866, 0.07887579, 0.047534  ,\n",
       "        0.08937037, 0.10757486, 0.13070704, 0.05893288, 0.04006911,\n",
       "        0.10108979, 0.09668772, 0.10332847, 0.06503708],\n",
       "       [0.03153591, 0.03955207, 0.03633327, 0.04960946, 0.03482308,\n",
       "        0.0533228 , 0.0480727 , 0.04724169, 0.03862009, 0.04668885,\n",
       "        0.03245546, 0.04472777, 0.02803181, 0.03000248],\n",
       "       [0.04752379, 0.10338294, 0.28655586, 0.04974849, 0.05161263,\n",
       "        0.05031179, 0.05609221, 0.06248747, 0.0643541 , 0.10978457,\n",
       "        0.02053341, 0.07043854, 0.06238384, 0.06110447],\n",
       "       [0.05681543, 0.03566969, 0.03945835, 0.04782307, 0.03628183,\n",
       "        0.03489491, 0.03097653, 0.03987999, 0.03344456, 0.03729931,\n",
       "        0.03939661, 0.05739555, 0.04318872, 0.02211146],\n",
       "       [0.05437016, 0.05026449, 0.04703517, 0.05953929, 0.04457894,\n",
       "        0.06834143, 0.05542699, 0.08630344, 0.04433798, 0.05174578,\n",
       "        0.06919474, 0.06336755, 0.05290022, 0.02847034],\n",
       "       [0.04826739, 0.06145978, 0.03042633, 0.05400148, 0.16430024,\n",
       "        0.05123456, 0.0343963 , 0.03718885, 0.10843493, 0.09499479,\n",
       "        0.09570075, 0.10011879, 0.05243567, 0.02430392],\n",
       "       [0.06833938, 0.03767269, 0.0500852 , 0.05131479, 0.03188588,\n",
       "        0.06184478, 0.06833369, 0.07255153, 0.0452697 , 0.02742783,\n",
       "        0.03678445, 0.07162145, 0.07127187, 0.02880199]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0050334 , 0.00235054, 0.00296817, ..., 0.00220805, 0.00335788,\n",
       "        0.00373513],\n",
       "       [0.00050124, 0.00154265, 0.00243333, ..., 0.00363363, 0.00257738,\n",
       "        0.00340801],\n",
       "       [0.0053127 , 0.01799806, 0.00125365, ..., 0.00480012, 0.00333179,\n",
       "        0.00360335],\n",
       "       ...,\n",
       "       [0.00149724, 0.00840936, 0.00200709, ..., 0.00659904, 0.00258421,\n",
       "        0.0026977 ],\n",
       "       [0.00196808, 0.00191371, 0.00114738, ..., 0.00224508, 0.00397609,\n",
       "        0.0028303 ],\n",
       "       [0.00330832, 0.00170234, 0.00080454, ..., 0.0060486 , 0.00260751,\n",
       "        0.00315783]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TINY = 1e-12\n",
    "\n",
    "def norm_entropy(p):\n",
    "    '''p: probabilities '''\n",
    "    n = p.shape[0]\n",
    "    return - p.dot(np.log(p + TINY) / np.log(n + TINY))\n",
    "\n",
    "def entropic_scores(r):\n",
    "    '''r: relative importances '''\n",
    "    r = np.abs(r)\n",
    "    ps = r / np.sum(r, axis=0) # 'probabilities'\n",
    "    hs = [1-norm_entropy(p) for p in ps.T]\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disentanglement 0.012734398602098549\n"
     ]
    }
   ],
   "source": [
    "disent_scores = entropic_scores(R.T)\n",
    "c_rel_importance = np.sum(R,1) / np.sum(R)\n",
    "disent_w_avg = np.sum(np.array(disent_scores) * c_rel_importance)\n",
    "print(\"disentanglement\", disent_w_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness 0.02218501073495232\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "complete_scores = entropic_scores(R)\n",
    "complete_scores = [v for v in complete_scores if not math.isnan(v)]\n",
    "complete_avg = np.mean(complete_scores)\n",
    "\n",
    "print(\"completeness\", complete_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [2:03:49<00:00, 99.06s/it]  \n"
     ]
    }
   ],
   "source": [
    "def compute_purity(loader, model):\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(312)] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets, attributes_all = batch[\"image\"].cuda(), batch[\"target\"], batch[\"attributes\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            target = targets[sample_id].item()\n",
    "            attributes = np.array(attributes_all[sample_id])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            for feature_id in range(n_features):\n",
    "\n",
    "                feature = features[feature_id]\n",
    "\n",
    "                for attribute_id, attribute in enumerate(attributes):\n",
    "                    value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "                    attribute_values[feature_id][attribute_id][0] += value_on\n",
    "\n",
    "                    value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "                    attribute_values[feature_id][attribute_id][1] += value_off\n",
    "    \n",
    "    for a in attribute_values:\n",
    "        a_ = [max(p) / len(train_set) for p in a]\n",
    "        features_to_attributes.append(a_)\n",
    "    \n",
    "    return features_to_attributes\n",
    "\n",
    "f2a = compute_purity(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attribute_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m         features_to_attributes\u001b[39m.\u001b[39mappend(a_)\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m features_to_attributes\n\u001b[0;32m---> 39\u001b[0m f2a \u001b[39m=\u001b[39m compute_purity(train_loader, model, attribute_mapping)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attribute_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_purity(loader, model, attribute_mapping):\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = [[[0, 0] for _ in range(len(attribute_mapping[0]))] for f in range(n_features)]\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, targets = batch[\"image\"].cuda(), batch[\"target\"]\n",
    "        N = images.shape[0]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            target = targets[sample_id].item()\n",
    "            attributes = np.array(attribute_mapping[target])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            for feature_id in range(n_features):\n",
    "\n",
    "                feature = features[feature_id]\n",
    "\n",
    "                for attribute_id, attribute in enumerate(attributes):\n",
    "                    value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "                    attribute_values[feature_id][attribute_id][0] += value_on\n",
    "\n",
    "                    value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "                    attribute_values[feature_id][attribute_id][1] += value_off\n",
    "    \n",
    "    for a in attribute_values:\n",
    "        a_ = [max(p) / len(train_set) for p in a]\n",
    "        features_to_attributes.append(a_)\n",
    "    \n",
    "    return features_to_attributes\n",
    "\n",
    "f2a = compute_purity(train_loader, model, attribute_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.5783433018127448\n"
     ]
    }
   ],
   "source": [
    "def find_best_alignment(features_to_attributes, iter_converge=20.0):\n",
    "    n_features, n_attributes = np.array(features_to_attributes).shape\n",
    "\n",
    "    features_to_attributes_ = list()\n",
    "    for feature_to_attributes in features_to_attributes:\n",
    "        feature_to_attributes_ = sorted([(idx, fa) for idx, fa in enumerate(feature_to_attributes)], key=lambda x: x[1], reverse=True)\n",
    "        features_to_attributes_.append(feature_to_attributes_)\n",
    "    \n",
    "    attributes_to_features = list(list() for _ in range(n_attributes))\n",
    "\n",
    "    for idx_feat, feature_to_attributes in enumerate(features_to_attributes_):\n",
    "        for idx_attr, score in feature_to_attributes:\n",
    "            attributes_to_features[idx_attr].append((idx_feat, score))\n",
    "    \n",
    "    attributes_to_features_ = list()\n",
    "    for attr2feature in attributes_to_features:\n",
    "        attributes_to_features_.append(sorted(attr2feature, key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    best_idx = list(None for _ in range(n_features))\n",
    "    best_scores = list(None for _ in range(n_features))\n",
    "\n",
    "    patience_left = iter_converge\n",
    "\n",
    "    while None in best_idx and patience_left > 0:\n",
    "        prev_best = [_ for _ in best_idx]\n",
    "\n",
    "        for feat_idx, f2a in enumerate(features_to_attributes_):\n",
    "            \n",
    "            if best_idx[feat_idx] is None:\n",
    "\n",
    "                for att_idx, score in f2a:\n",
    "\n",
    "                    if att_idx not in best_idx:\n",
    "                        best_idx[feat_idx] = att_idx\n",
    "                        best_scores[feat_idx] = score\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        idx_other = best_idx.index(att_idx)\n",
    "                        score_other = best_scores[idx_other]\n",
    "\n",
    "                        if score > score_other:\n",
    "                            best_idx[feat_idx] = att_idx\n",
    "                            best_scores[feat_idx] = score\n",
    "\n",
    "                            best_idx[idx_other] = None\n",
    "                            best_scores[idx_other] = None\n",
    "                            break\n",
    "        \n",
    "        if best_idx == prev_best:\n",
    "            patience_left -= 1\n",
    "        else:\n",
    "            patience_left = iter_converge\n",
    "        \n",
    "    return list(zip(best_idx, best_scores))\n",
    "\n",
    "    \n",
    "result = find_best_alignment(f2a)\n",
    "\n",
    "scores = [b for _, b in result if b is not None]\n",
    "print(\"Purity: \", np.array(scores).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Shapes dataset\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | cluster | align | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.830247` | `0.767724` | `0.465324 `| `0.481560` |  `A`  | `-`  | `outputs/2023-05-22/08-37-36` |\n",
    "| Baseline | `gumbel` |   `-`   |   `-`   |  `-`   | `0.404321`  | `0.828083` | `0.316362` | `0.276083` | `A` | `-` |  `outputs/2023-05-22/08-49-23`  |\n",
    "| Framework | `sigmoid` | `softmax`   |  `false`   |     `false`   | `0.969136`  | `0.636225`  | `0.437534` | `0.408124` | `B` | `D` | `outputs/2023-05-22/08-18-17` |  \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `false`  |   `0.848765`  |  `0.763983`    | `0.651922` | `0.611969` |   `B` |  `C`   |  `outputs/2023-05-22/08-04-48`  |  \n",
    "| Framework | `gumbel` |  `entmax`   |  `false`   |    `false`  |   `0.842593`  |  `0.748309`     | `0.742202` | `0.736384` |  `A`  |  `B`  |  `outputs/2023-05-22/09-13-40`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `true`   |    `false`  |   `0.731482`  |  `0.707190`     | `0.670618` | `0.637436` |   `A` |  `B`  |  `outputs/2023-05-22/09-38-41`  | \n",
    "| Framework | `gumbel` |  `entmax`   |  `true`   |    `false`  |   `0.586420`  |  `0.691018`     | `0.582086` | `0.564636` |  `A`  |  `B`  |  `outputs/2023-05-22/11-03-11`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `true`  |   `0.814815`  |  `0.726690`    | `0.708535` | `0.673539` |  `A` | `D` |  `outputs/2023-05-22/09-53-54`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CUB-200 \n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.805452` | `0.573071` | `0.189394`| `0.196021` | `outputs/2023-05-26/07-31-18` |\n",
    "| Baseline | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.765`  | `0.578` | `0.193078` | `0.201281` | `outputs/2023-05-28/09-21-34`  |\n",
    "| Framework | `gumbel (0.5)` |  `entmax`   |  `false`   |    `false`  |   `0.773003`  |  `0.593836`    | `0.229795` | `0.255646` |   `outputs/2023-05-27/10-34-06`  | \n",
    "| Framework | `gumbel (0.01)` |  `entmax`   |  `false`   |    `false`  |   `0.726`  |  `0.657`    | `X` | `X` |   `outputs/2023-05-27/19-41-06`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MIMIC-CXR\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.768` |  `0.0366`| `0.0447` | `outputs/2023-06-01/12-16-30` |\n",
    "| Framework | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.749` | `0.0435` | `0.0545` | `outputs/2023-06-01/13-18-08`  |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bottleneck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
