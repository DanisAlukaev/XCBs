{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring disentanglement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify path to an experiment in a format `outputs/YYYY-MM-DD/HH-MM-SS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = \"outputs/2023-06-02/17-54-32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import load_experiment\n",
    "from extract import prepare_data_dci, fit_linear_model, compute_completeness, compute_disentanglement, compute_informativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching configuration...\n",
      "Loading datamodule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 2700/2700 [00:00<00:00, 9265.14it/s]\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of vocab:  53\n",
      "Max len of caption:  12\n",
      "Index for <pad>: [0]\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_task' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_task'])`.\n",
      "  rank_zero_warn(\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_tie' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_tie'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "PATH_PREFIX = \"/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/autoconcept\"\n",
    "dm, model = load_experiment(os.path.join(PATH_PREFIX, EXPERIMENT_PATH))\n",
    "train_loader = dm.train_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "train_set = train_loader.dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prepare_data_dci(train_loader, model)\n",
    "X_test, y_test = prepare_data_dci(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "R, errors = fit_linear_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disentanglement: 0.539\n"
     ]
    }
   ],
   "source": [
    "disentanglement = compute_disentanglement(R)\n",
    "print(f\"Disentanglement: {disentanglement:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.513\n"
     ]
    }
   ],
   "source": [
    "completeness = compute_completeness(R)\n",
    "print(f\"Completeness: {completeness:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informativeness (NRMSE): 0.180\n"
     ]
    }
   ],
   "source": [
    "informativeness = compute_informativeness(errors)\n",
    "print(f\"Informativeness (NRMSE): {informativeness:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:15<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_purity(loader, model):\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = None\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, attributes_all = batch[\"image\"].cuda(), batch[\"attributes\"]\n",
    "        N = images.shape[0]\n",
    "        n_attributes = np.array(attributes_all).shape[1]\n",
    "\n",
    "        if attribute_values is None:\n",
    "            attribute_values = [[[0, 0] for _ in range(n_attributes)] for f in range(n_features)]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            attributes = np.array(attributes_all[sample_id])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            for feature_id in range(n_features):\n",
    "\n",
    "                feature = features[feature_id]\n",
    "\n",
    "                for attribute_id, attribute in enumerate(attributes):\n",
    "                    value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "                    attribute_values[feature_id][attribute_id][0] += value_on\n",
    "\n",
    "                    value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "                    attribute_values[feature_id][attribute_id][1] += value_off\n",
    "    \n",
    "    for a in attribute_values:\n",
    "        a_ = [max(p) / len(train_set) for p in a]\n",
    "        features_to_attributes.append(a_)\n",
    "    \n",
    "    return features_to_attributes\n",
    "\n",
    "f2a = compute_purity(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.7787873725699388\n"
     ]
    }
   ],
   "source": [
    "def find_best_alignment(features_to_attributes, iter_converge=20.0):\n",
    "    n_features, n_attributes = np.array(features_to_attributes).shape\n",
    "\n",
    "    features_to_attributes_ = list()\n",
    "    for feature_to_attributes in features_to_attributes:\n",
    "        feature_to_attributes_ = sorted([(idx, fa) for idx, fa in enumerate(feature_to_attributes)], key=lambda x: x[1], reverse=True)\n",
    "        features_to_attributes_.append(feature_to_attributes_)\n",
    "    \n",
    "    attributes_to_features = list(list() for _ in range(n_attributes))\n",
    "\n",
    "    for idx_feat, feature_to_attributes in enumerate(features_to_attributes_):\n",
    "        for idx_attr, score in feature_to_attributes:\n",
    "            attributes_to_features[idx_attr].append((idx_feat, score))\n",
    "    \n",
    "    attributes_to_features_ = list()\n",
    "    for attr2feature in attributes_to_features:\n",
    "        attributes_to_features_.append(sorted(attr2feature, key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    best_idx = list(None for _ in range(n_features))\n",
    "    best_scores = list(None for _ in range(n_features))\n",
    "\n",
    "    patience_left = iter_converge\n",
    "\n",
    "    while None in best_idx and patience_left > 0:\n",
    "        prev_best = [_ for _ in best_idx]\n",
    "\n",
    "        for feat_idx, f2a in enumerate(features_to_attributes_):\n",
    "            \n",
    "            if best_idx[feat_idx] is None:\n",
    "\n",
    "                for att_idx, score in f2a:\n",
    "\n",
    "                    if att_idx not in best_idx:\n",
    "                        best_idx[feat_idx] = att_idx\n",
    "                        best_scores[feat_idx] = score\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        idx_other = best_idx.index(att_idx)\n",
    "                        score_other = best_scores[idx_other]\n",
    "\n",
    "                        if score > score_other:\n",
    "                            best_idx[feat_idx] = att_idx\n",
    "                            best_scores[feat_idx] = score\n",
    "\n",
    "                            best_idx[idx_other] = None\n",
    "                            best_scores[idx_other] = None\n",
    "                            break\n",
    "        \n",
    "        if best_idx == prev_best:\n",
    "            patience_left -= 1\n",
    "        else:\n",
    "            patience_left = iter_converge\n",
    "        \n",
    "    return list(zip(best_idx, best_scores))\n",
    "\n",
    "    \n",
    "result = find_best_alignment(f2a)\n",
    "\n",
    "scores = [b for _, b in result if b is not None and b != 0]\n",
    "print(\"Purity: \", np.array(scores).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Shapes dataset\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | cluster | align | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.830247` | `0.767724` | `0.465324 `| `0.481560` |  `A`  | `-`  | `outputs/2023-05-22/08-37-36` |\n",
    "| Baseline | `gumbel` |   `-`   |   `-`   |  `-`   | `0.404321`  | `0.828083` | `0.316362` | `0.276083` | `A` | `-` |  `outputs/2023-05-22/08-49-23`  |\n",
    "| Framework | `sigmoid` | `softmax`   |  `false`   |     `false`   | `0.969136`  | `0.636225`  | `0.437534` | `0.408124` | `B` | `D` | `outputs/2023-05-22/08-18-17` |  \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `false`  |   `0.848765`  |  `0.763983`    | `0.651922` | `0.611969` |   `B` |  `C`   |  `outputs/2023-05-22/08-04-48`  |  \n",
    "| Framework | `gumbel` |  `entmax`   |  `false`   |    `false`  |   `0.842593`  |  `0.748309`     | `0.742202` | `0.736384` |  `A`  |  `B`  |  `outputs/2023-05-22/09-13-40`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `true`   |    `false`  |   `0.731482`  |  `0.707190`     | `0.670618` | `0.637436` |   `A` |  `B`  |  `outputs/2023-05-22/09-38-41`  | \n",
    "| Framework | `gumbel` |  `entmax`   |  `true`   |    `false`  |   `0.586420`  |  `0.691018`     | `0.582086` | `0.564636` |  `A`  |  `B`  |  `outputs/2023-05-22/11-03-11`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `true`  |   `0.814815`  |  `0.726690`    | `0.708535` | `0.673539` |  `A` | `D` |  `outputs/2023-05-22/09-53-54`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CUB-200 \n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.805452` | `0.573071` | `0.189394`| `0.196021` | `outputs/2023-05-26/07-31-18` |\n",
    "| Baseline | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.765`  | `0.578` | `0.193078` | `0.201281` | `outputs/2023-05-28/09-21-34`  |\n",
    "| Framework | `gumbel (0.5)` |  `entmax`   |  `false`   |    `false`  |   `0.773003`  |  `0.593836`    | `0.229795` | `0.255646` |   `outputs/2023-05-27/10-34-06`  | \n",
    "| Framework | `gumbel (0.01)` |  `entmax`   |  `false`   |    `false`  |   `0.726`  |  `0.657`    | `X` | `X` |   `outputs/2023-05-27/19-41-06`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MIMIC-CXR\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.768` |  `0.0164`| `0.0085` | `outputs/2023-06-01/12-16-30` |\n",
    "| Framework | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.749` | `0.0222` | `0.0124` | `outputs/2023-06-01/13-18-08`  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bottleneck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
