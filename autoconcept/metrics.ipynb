{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring disentanglement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify path to an experiment in a format `outputs/YYYY-MM-DD/HH-MM-SS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = \"outputs/2023-06-04/15-33-19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import load_experiment\n",
    "from extract import prepare_data_dci, fit_linear_model, compute_completeness, compute_disentanglement, compute_informativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching configuration...\n",
      "Loading datamodule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 2700/2700 [00:00<00:00, 9526.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of vocab:  53\n",
      "Max len of caption:  12\n",
      "Index for <pad>: [0]\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_task' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_task'])`.\n",
      "  rank_zero_warn(\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_tie' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_tie'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "PATH_PREFIX = \"/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/autoconcept\"\n",
    "dm, model = load_experiment(os.path.join(PATH_PREFIX, EXPERIMENT_PATH))\n",
    "train_loader = dm.train_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "train_set = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching configuration...\n",
      "Loading datamodule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 2700/2700 [00:00<00:00, 9475.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of vocab:  53\n",
      "Max len of caption:  12\n",
      "Index for <pad>: [0]\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_task' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_task'])`.\n",
      "  rank_zero_warn(\n",
      "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'criterion_tie' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion_tie'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "PATH_PREFIX = \"/home/danis/Projects/AlphaCaption/AutoConceptBottleneck/autoconcept\"\n",
    "EXPERIMENT_PATH = \"outputs/2023-06-21/12-37-03\"\n",
    "dm, _ = load_experiment(os.path.join(PATH_PREFIX, EXPERIMENT_PATH))\n",
    "train_loader = dm.train_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "train_set = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:04<00:39,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:05<00:15,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:05<00:07,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:04,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:05<00:02,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:06<00:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:06<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:06<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "(19,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "targets = list()\n",
    "preds = list()\n",
    "\n",
    "is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "for batch in tqdm(test_loader):\n",
    "    images, target = batch[\"image\"].cuda(), batch[\"target\"]\n",
    "    N = images.shape[0]\n",
    "\n",
    "    batch_features = model.main.inference(\n",
    "                images)[0].cpu().detach()\n",
    "\n",
    "    pred = torch.argmax(batch_features, dim=1).numpy()\n",
    "    print(pred.shape)\n",
    "\n",
    "    \n",
    "    preds += list(pred)\n",
    "    targets += list(target)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 2, 5, 4, 2, 3, 4, 4, 3, 2],\n",
       " [tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10], targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21092278719397364"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(targets, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds == targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prepare_data_dci(train_loader, model)\n",
    "X_test, y_test = prepare_data_dci(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "R, errors = fit_linear_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disentanglement: 0.547\n"
     ]
    }
   ],
   "source": [
    "disentanglement = compute_disentanglement(R)\n",
    "print(f\"Disentanglement: {disentanglement:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.488\n"
     ]
    }
   ],
   "source": [
    "completeness = compute_completeness(R)\n",
    "print(f\"Completeness: {completeness:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informativeness (NRMSE): 0.244\n"
     ]
    }
   ],
   "source": [
    "informativeness = compute_informativeness(errors)\n",
    "print(f\"Informativeness (NRMSE): {informativeness:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:15<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_purity(loader, model):\n",
    "    is_framework = hasattr(model.main, \"concept_extractor\")\n",
    "    n_features = model.main.feature_extractor.main.fc.out_features\n",
    "    \n",
    "    features_to_attributes = list()\n",
    "    attribute_values = None\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        images, attributes_all = batch[\"image\"].cuda(), batch[\"attributes\"]\n",
    "        N = images.shape[0]\n",
    "        n_attributes = np.array(attributes_all).shape[1]\n",
    "\n",
    "        if attribute_values is None:\n",
    "            attribute_values = [[[0, 0] for _ in range(n_attributes)] for f in range(n_features)]\n",
    "        \n",
    "        if is_framework:\n",
    "            batch_features = model.main.inference(images)[1].cpu().detach().numpy()\n",
    "        else:\n",
    "            batch_features = model(images)[\"concept_probs\"].cpu().detach().numpy()\n",
    "        \n",
    "        for sample_id in range(N):\n",
    "            attributes = np.array(attributes_all[sample_id])\n",
    "            features = batch_features[sample_id]\n",
    "\n",
    "            for feature_id in range(n_features):\n",
    "\n",
    "                feature = features[feature_id]\n",
    "\n",
    "                for attribute_id, attribute in enumerate(attributes):\n",
    "                    value_on = attribute * feature + (1 - attribute) * (1 - feature)\n",
    "                    attribute_values[feature_id][attribute_id][0] += value_on\n",
    "\n",
    "                    value_off = attribute * (1 - feature) + (1 - attribute) * feature\n",
    "                    attribute_values[feature_id][attribute_id][1] += value_off\n",
    "    \n",
    "    for a in attribute_values:\n",
    "        a_ = [max(p) / len(train_set) for p in a]\n",
    "        features_to_attributes.append(a_)\n",
    "    \n",
    "    return features_to_attributes\n",
    "\n",
    "f2a = compute_purity(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.7787873725699388\n"
     ]
    }
   ],
   "source": [
    "def find_best_alignment(features_to_attributes, iter_converge=20.0):\n",
    "    n_features, n_attributes = np.array(features_to_attributes).shape\n",
    "\n",
    "    features_to_attributes_ = list()\n",
    "    for feature_to_attributes in features_to_attributes:\n",
    "        feature_to_attributes_ = sorted([(idx, fa) for idx, fa in enumerate(feature_to_attributes)], key=lambda x: x[1], reverse=True)\n",
    "        features_to_attributes_.append(feature_to_attributes_)\n",
    "    \n",
    "    attributes_to_features = list(list() for _ in range(n_attributes))\n",
    "\n",
    "    for idx_feat, feature_to_attributes in enumerate(features_to_attributes_):\n",
    "        for idx_attr, score in feature_to_attributes:\n",
    "            attributes_to_features[idx_attr].append((idx_feat, score))\n",
    "    \n",
    "    attributes_to_features_ = list()\n",
    "    for attr2feature in attributes_to_features:\n",
    "        attributes_to_features_.append(sorted(attr2feature, key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    best_idx = list(None for _ in range(n_features))\n",
    "    best_scores = list(None for _ in range(n_features))\n",
    "\n",
    "    patience_left = iter_converge\n",
    "\n",
    "    while None in best_idx and patience_left > 0:\n",
    "        prev_best = [_ for _ in best_idx]\n",
    "\n",
    "        for feat_idx, f2a in enumerate(features_to_attributes_):\n",
    "            \n",
    "            if best_idx[feat_idx] is None:\n",
    "\n",
    "                for att_idx, score in f2a:\n",
    "\n",
    "                    if att_idx not in best_idx:\n",
    "                        best_idx[feat_idx] = att_idx\n",
    "                        best_scores[feat_idx] = score\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        idx_other = best_idx.index(att_idx)\n",
    "                        score_other = best_scores[idx_other]\n",
    "\n",
    "                        if score > score_other:\n",
    "                            best_idx[feat_idx] = att_idx\n",
    "                            best_scores[feat_idx] = score\n",
    "\n",
    "                            best_idx[idx_other] = None\n",
    "                            best_scores[idx_other] = None\n",
    "                            break\n",
    "        \n",
    "        if best_idx == prev_best:\n",
    "            patience_left -= 1\n",
    "        else:\n",
    "            patience_left = iter_converge\n",
    "        \n",
    "    return list(zip(best_idx, best_scores))\n",
    "\n",
    "    \n",
    "result = find_best_alignment(f2a)\n",
    "\n",
    "scores = [b for _, b in result if b is not None and b != 0]\n",
    "print(\"Purity: \", np.array(scores).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Shapes dataset\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | cluster | align | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.830247` | `0.767724` | `0.465324 `| `0.481560` |  `A`  | `-`  | `outputs/2023-05-22/08-37-36` |\n",
    "| Baseline | `gumbel` |   `-`   |   `-`   |  `-`   | `0.404321`  | `0.828083` | `0.316362` | `0.276083` | `A` | `-` |  `outputs/2023-05-22/08-49-23`  |\n",
    "| Framework | `sigmoid` | `softmax`   |  `false`   |     `false`   | `0.969136`  | `0.636225`  | `0.437534` | `0.408124` | `B` | `D` | `outputs/2023-05-22/08-18-17` |  \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `false`  |   `0.848765`  |  `0.763983`    | `0.651922` | `0.611969` |   `B` |  `C`   |  `outputs/2023-05-22/08-04-48`  |  \n",
    "| Framework | `gumbel` |  `entmax`   |  `false`   |    `false`  |   `0.842593`  |  `0.748309`     | `0.742202` | `0.736384` |  `A`  |  `B`  |  `outputs/2023-05-22/09-13-40`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `true`   |    `false`  |   `0.731482`  |  `0.707190`     | `0.670618` | `0.637436` |   `A` |  `B`  |  `outputs/2023-05-22/09-38-41`  | \n",
    "| Framework | `gumbel` |  `entmax`   |  `true`   |    `false`  |   `0.586420`  |  `0.691018`     | `0.582086` | `0.564636` |  `A`  |  `B`  |  `outputs/2023-05-22/11-03-11`  | \n",
    "| Framework | `gumbel` |  `softmax`   |  `false`   |    `true`  |   `0.814815`  |  `0.726690`    | `0.708535` | `0.673539` |  `A` | `D` |  `outputs/2023-05-22/09-53-54`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CUB-200 \n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | purity | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.805452` | `0.573071` | `0.189394`| `0.196021` | `outputs/2023-05-26/07-31-18` |\n",
    "| Baseline | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.765`  | `0.578` | `0.193078` | `0.201281` | `outputs/2023-05-28/09-21-34`  |\n",
    "| Framework | `gumbel (0.5)` |  `entmax`   |  `false`   |    `false`  |   `0.773003`  |  `0.593836`    | `0.229795` | `0.255646` |   `outputs/2023-05-27/10-34-06`  | \n",
    "| Framework | `gumbel (0.01)` |  `entmax`   |  `false`   |    `false`  |   `0.726`  |  `0.657`    | `X` | `X` |   `outputs/2023-05-27/19-41-06`  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MIMIC-CXR\n",
    "\n",
    "| model | activation | norm_fn | slot_norm | reg_dist | f1-score | disentanglement | completeness | directory |\n",
    "|:-----------|:----:|:----:|:----:|:----:|:----:|:-------:|:-------:|:-----------|\n",
    "| Baseline | `sigmoid` |   `-`   |  `-`   |   `-`   | `0.768` |  `0.0164`| `0.0085` | `outputs/2023-06-01/12-16-30` |\n",
    "| Framework | `gumbel (0.01)` |   `-`   |   `-`   |  `-`   | `0.749` | `0.0222` | `0.0124` | `outputs/2023-06-01/13-18-08`  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "\n",
    "\"E49-SHP\":\n",
    "[[0.981131, 0.873248, 0.973656, 0.924189, 0.971781],\n",
    "[0.663345, 0.394986, 0.387052, 0.561059, 0.575503],\n",
    "[0.505478, 0.364848, 0.391295, 0.460447, 0.642119],\n",
    "[0.172368, 0.280508, 0.169319, 0.192731, 0.182917]],\n",
    "\n",
    "\"E50-SHP\":\n",
    "[[0.981165, 0.971696, 0.990583, 0.963805, 0.983096],\n",
    "[0.588585, 0.573661, 0.56222, 0.553471, 0.477187],\n",
    "[0.46946, 0.632319, 0.498188, 0.485164, 0.380766],\n",
    "[0.143945, 0.175667, 0.154161, 0.149143, 0.161818]],\n",
    "\n",
    "\"E51-SHP\":\n",
    "[[0.447716, 0.389919, 0.472793, 0.665221, 0.489999],\n",
    "[0.432098, 0.37835, 0.430014, 0.495095, 0.528005],\n",
    "[0.419269, 0.382079, 0.424006, 0.461387, 0.431549],\n",
    "[0.477292, 0.476659, 0.459475, 0.364721, 0.448022]],\n",
    "\n",
    "\"E52-SHP\":\n",
    "[[0.942825, 0.968106, 0.988683, 0.983082, 0.9887],\n",
    "[0.472531, 0.45885, 0.638394, 0.511719, 0.509037],\n",
    "[0.447773, 0.461443, 0.549162, 0.533417, 0.422075],\n",
    "[0.231318, 0.14777, 0.142614, 0.159164, 0.139041]],\n",
    "\n",
    "\"E53-SHP\":\n",
    "[[0.881701, 0.827895, 0.879056, 0.874072, 0.682161],\n",
    "[0.627323, 0.667616, 0.595665, 0.850418, 0.534167],\n",
    "[0.529322, 0.517727, 0.527888, 0.692079, 0.511404],\n",
    "[0.139276, 0.145541, 0.137512, 0.162982, 0.205537]],\n",
    "\n",
    "\"E54-SHP\":\n",
    "[[0.575949, 0.35089, 0.582664, 0.482592, 0.376687],\n",
    "[0.485671, 0.460129, 0.661162, 0.617536, 0.583347],\n",
    "[0.519757, 0.406376, 0.518161, 0.522811, 0.61405],\n",
    "[0.177332, 0.366635, 0.146314, 0.171029, 0.265272]],\n",
    "\n",
    "\"E55-SHP\":\n",
    "[[0.614845, 0.42983, 0.584451, 0.477093, 0.393848],\n",
    "[0.540889, 0.504733, 0.678941, 0.546654, 0.577525],\n",
    "[0.425633, 0.505349, 0.588776, 0.478584, 0.560115],\n",
    "[0.226377, 0.231023, 0.146473, 0.176644, 0.241622]],\n",
    "\n",
    "\"E56-SHP\":\n",
    "[[0.862637, 0.829518, 0.862029, 0.850979, 0.740367],\n",
    "[0.618041, 0.618922, 0.505485, 0.73972, 0.538934],\n",
    "[0.460178, 0.541834, 0.441986, 0.625805, 0.513224],\n",
    "[0.13346, 0.175929, 0.154805, 0.153977, 0.179752]],\n",
    "\n",
    "\"E57-SHP\":\n",
    "[[0.494562, 0.657113, 0.52312, 0.514724, 0.508858],\n",
    "[0.586914, 0.810653, 0.365879, 0.488906, 0.59746],\n",
    "[0.54572, 0.579612, 0.399097, 0.43978, 0.65056],\n",
    "[0.348297, 0.145581, 0.318479, 0.254663, 0.204913]],\n",
    "\n",
    "\"E58-SHP\":\n",
    "[[0.439655, 0.605264, 0.416931, 0.468073, 0.512713],\n",
    "[0.525453, 0.775373, 0.408299, 0.5834, 0.549561],\n",
    "[0.486188, 0.379191, 0.408362, 0.547149, 0.581411],\n",
    "[0.319103, 0.174612, 0.328444, 0.241011, 0.177954]],\n",
    "\n",
    "\"E59-SHP\":\n",
    "[[0.605599, 0.6777, 0.646318, 0.581926, 0.673149],\n",
    "[0.731953, 0.801716, 0.782887, 0.706306, 0.739048],\n",
    "[0.776975, 0.721015, 0.769809, 0.739891, 0.747892],\n",
    "[0.086086, 0.078189, 0.08505, 0.050539, 0.105751]],\n",
    "\n",
    "\"E60-SHP\":\n",
    "[[0.455141, 0.523521, 0.497093, 0.494261, 0.47096],\n",
    "[0.564572, 0.594083, 0.54585, 0.645181, 0.679455],\n",
    "[0.503765, 0.468938, 0.542489, 0.407685, 0.668507],\n",
    "[0.283051, 0.184142, 0.215551, 0.276161, 0.207509]],\n",
    "\n",
    "\"E61-SHP\":\n",
    "[[0.881701, 0.827895, 0.879056, 0.874072, 0.682161],\n",
    "[0.627323, 0.667616, 0.595665, 0.850418, 0.534167],\n",
    "[0.529322, 0.517727, 0.527888, 0.692079, 0.511404],\n",
    "[0.139276, 0.145541, 0.137512, 0.162982, 0.205537]],\n",
    "\n",
    "\"E62-SHP\":\n",
    "[[0.862637, 0.829518, 0.862029, 0.850979, 0.740367],\n",
    "[0.618041, 0.618922, 0.505485, 0.73972, 0.538934],\n",
    "[0.460178, 0.541834, 0.441986, 0.625805, 0.513224],\n",
    "[0.13346, 0.175929, 0.154805, 0.153977, 0.179752]]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.75 ± 0.01\n",
      "disentanglement: 0.02 ± 0.00\n",
      "completeness:0.01 ± 0.00\n",
      "informativeness: 1.00 ± 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f1 = np.array([0.754, 0.739333, 0.742667, 0.751333, 0.778])\n",
    "print(f\"f1: {f1.mean():.2f} ± {f1.std():.2f}\")\n",
    "\n",
    "D = np.array([0.019657, 0.020572, 0.017048, 0.022053, 0.022829])\n",
    "print(f\"disentanglement: {D.mean():.2f} ± {D.std():.2f}\")\n",
    "\n",
    "C = np.array([0.011669, 0.015166, 0.011676, 0.011553, 0.013123])\n",
    "print(f\"completeness:{C.mean():.2f} ± {C.std():.2f}\")\n",
    "\n",
    "I = np.array([0.991455, 1.000082, 0.999471, 0.993454, 0.993892])\n",
    "print(f\"informativeness: {I.mean():.2f} ± {I.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E49-SHP\n",
      "f1: 0.94 ± 0.04\n",
      "disentanglement: 0.52 ± 0.11\n",
      "completeness:0.47 ± 0.10\n",
      "informativeness: 0.20 ± 0.04\n",
      "\n",
      "E50-SHP\n",
      "f1: 0.98 ± 0.01\n",
      "disentanglement: 0.55 ± 0.04\n",
      "completeness:0.49 ± 0.08\n",
      "informativeness: 0.16 ± 0.01\n",
      "\n",
      "E51-SHP\n",
      "f1: 0.49 ± 0.09\n",
      "disentanglement: 0.45 ± 0.05\n",
      "completeness:0.42 ± 0.03\n",
      "informativeness: 0.45 ± 0.04\n",
      "\n",
      "E52-SHP\n",
      "f1: 0.97 ± 0.02\n",
      "disentanglement: 0.52 ± 0.06\n",
      "completeness:0.48 ± 0.05\n",
      "informativeness: 0.16 ± 0.03\n",
      "\n",
      "E53-SHP\n",
      "f1: 0.83 ± 0.08\n",
      "disentanglement: 0.66 ± 0.11\n",
      "completeness:0.56 ± 0.07\n",
      "informativeness: 0.16 ± 0.03\n",
      "\n",
      "E54-SHP\n",
      "f1: 0.47 ± 0.10\n",
      "disentanglement: 0.56 ± 0.08\n",
      "completeness:0.52 ± 0.07\n",
      "informativeness: 0.23 ± 0.08\n",
      "\n",
      "E55-SHP\n",
      "f1: 0.50 ± 0.09\n",
      "disentanglement: 0.57 ± 0.06\n",
      "completeness:0.51 ± 0.06\n",
      "informativeness: 0.20 ± 0.04\n",
      "\n",
      "E56-SHP\n",
      "f1: 0.83 ± 0.05\n",
      "disentanglement: 0.60 ± 0.08\n",
      "completeness:0.52 ± 0.07\n",
      "informativeness: 0.16 ± 0.02\n",
      "\n",
      "E57-SHP\n",
      "f1: 0.54 ± 0.06\n",
      "disentanglement: 0.57 ± 0.15\n",
      "completeness:0.52 ± 0.09\n",
      "informativeness: 0.25 ± 0.07\n",
      "\n",
      "E58-SHP\n",
      "f1: 0.49 ± 0.07\n",
      "disentanglement: 0.57 ± 0.12\n",
      "completeness:0.48 ± 0.08\n",
      "informativeness: 0.25 ± 0.07\n",
      "\n",
      "E59-SHP\n",
      "f1: 0.64 ± 0.04\n",
      "disentanglement: 0.75 ± 0.03\n",
      "completeness:0.75 ± 0.02\n",
      "informativeness: 0.08 ± 0.02\n",
      "\n",
      "E60-SHP\n",
      "f1: 0.49 ± 0.02\n",
      "disentanglement: 0.61 ± 0.05\n",
      "completeness:0.52 ± 0.09\n",
      "informativeness: 0.23 ± 0.04\n",
      "\n",
      "E61-SHP\n",
      "f1: 0.83 ± 0.08\n",
      "disentanglement: 0.66 ± 0.11\n",
      "completeness:0.56 ± 0.07\n",
      "informativeness: 0.16 ± 0.03\n",
      "\n",
      "E62-SHP\n",
      "f1: 0.83 ± 0.05\n",
      "disentanglement: 0.60 ± 0.08\n",
      "completeness:0.52 ± 0.07\n",
      "informativeness: 0.16 ± 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(49, 63):\n",
    "    exp = f\"E{i}-SHP\"\n",
    "    res = results[exp]\n",
    "    f1 = np.array(res[0])\n",
    "    D = np.array(res[1])\n",
    "    C = np.array(res[2])\n",
    "    I = np.array(res[3])\n",
    "    print(exp)\n",
    "    print(f\"f1: {f1.mean():.2f} ± {f1.std():.2f}\")\n",
    "    print(f\"disentanglement: {D.mean():.2f} ± {D.std():.2f}\")\n",
    "    print(f\"completeness:{C.mean():.2f} ± {C.std():.2f}\")\n",
    "    print(f\"informativeness: {I.mean():.2f} ± {I.std():.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E48-SHP': [[0.911634, 0.924783, 0.916744, 0.915334, 0.888455],\n",
       "  [0.714322, 0.756357, 0.723712, 0.782168, 0.762912],\n",
       "  [0.552646, 0.678377, 0.751705, 0.82064, 0.826717],\n",
       "  [0.100274, 0.057948, 0.076777, 0.077664, 0.080682]],\n",
       " 'E47-SHP': [[0.926393, 0.935305, 0.947202, 0.93199, 0.912968],\n",
       "  [0.790332, 0.801184, 0.795011, 0.782948, 0.72203],\n",
       "  [0.512468, 0.763281, 0.81812, 0.861406, 0.726697],\n",
       "  [0.08803, 0.038964, 0.079581, 0.066335, 0.080838]],\n",
       " 'E46-SHP': [[0.609361, 0.688224, 0.704962, 0.598473, 0.712253],\n",
       "  [0.75557, 0.646946, 0.673611, 0.629381, 0.735236],\n",
       "  [0.829323, 0.587759, 0.763867, 0.694606, 0.764935],\n",
       "  [0.122514, 0.068016, 0.076611, 0.036437, 0.111215]],\n",
       " 'E45-SHP': [[0.605599, 0.6777, 0.646318, 0.581926, 0.673149],\n",
       "  [0.731953, 0.801716, 0.782887, 0.706306, 0.739048],\n",
       "  [0.776975, 0.721015, 0.769809, 0.739891, 0.747892],\n",
       "  [0.086086, 0.078189, 0.08505, 0.050539, 0.105751]],\n",
       " 'E44-SHP': [[0.714243, 0.746843, 0.665712, 0.689275, 0.79202],\n",
       "  [0.833282, 0.685071, 0.736512, 0.774483, 0.662222],\n",
       "  [0.933392, 0.537353, 0.842934, 0.88213, 0.772932],\n",
       "  [0.056083, 0.072866, 0.062078, 0.0672, 0.114144]],\n",
       " 'E43-SHP': [[0.796979, 0.730684, 0.68999, 0.781944, 0.729565],\n",
       "  [0.784924, 0.758952, 0.681042, 0.613127, 0.73328],\n",
       "  [0.80317, 0.704489, 0.726528, 0.595106, 0.704466],\n",
       "  [0.099218, 0.082034, 0.084849, 0.073327, 0.115084]],\n",
       " 'E42-SHP': [[0.911634, 0.924783, 0.916744, 0.915334, 0.888455],\n",
       "  [0.714322, 0.756357, 0.723712, 0.782168, 0.762912],\n",
       "  [0.552646, 0.678377, 0.751705, 0.82064, 0.826717],\n",
       "  [0.100274, 0.057948, 0.076777, 0.077664, 0.080682]],\n",
       " 'E41-SHP': [[0.593661, 0.755893, 0.66464, 0.631355, 0.602499],\n",
       "  [0.574505, 0.679759, 0.72415, 0.703409, 0.76411],\n",
       "  [0.633967, 0.72005, 0.770474, 0.758989, 0.701181],\n",
       "  [0.120356, 0.071099, 0.07496, 0.078137, 0.095788]],\n",
       " 'E40-SHP': [[0.586194, 0.686391, 0.635703, 0.592576, 0.58641],\n",
       "  [0.612219, 0.678793, 0.706593, 0.648599, 0.699692],\n",
       "  [0.67942, 0.733373, 0.765801, 0.738637, 0.612774],\n",
       "  [0.086265, 0.037829, 0.121043, 0.090218, 0.092392]],\n",
       " 'E39-SHP': [[0.926393, 0.935305, 0.947202, 0.93199, 0.912968],\n",
       "  [0.790332, 0.801184, 0.795011, 0.782948, 0.72203],\n",
       "  [0.512468, 0.763281, 0.81812, 0.861406, 0.726697],\n",
       "  [0.08803, 0.038964, 0.079581, 0.066335, 0.080838]],\n",
       " 'E38-SHP': [[0.992482, 0.99435, 0.998117, 0.994349, 0.992466],\n",
       "  [0.554426, 0.675867, 0.664008, 0.778436, 0.523756],\n",
       "  [0.609996, 0.69221, 0.704597, 0.706883, 0.688129],\n",
       "  [0.102797, 0.103424, 0.019946, 0.072356, 0.086632]],\n",
       " 'E37-SHP': [[0.988745, 0.994365, 0.994366, 0.998117, 0.992466],\n",
       "  [0.526579, 0.489267, 0.506091, 0.523942, 0.50006],\n",
       "  [0.504826, 0.540975, 0.52436, 0.664761, 0.575982],\n",
       "  [0.092013, 0.114545, 0.075384, 0.046922, 0.083993]],\n",
       " 'E36-SHP': [[0.996234, 0.996233, 0.99435, 0.996233, 0.998117],\n",
       "  [0.578681, 0.806794, 0.652738, 0.775874, 0.575105],\n",
       "  [0.677627, 0.706332, 0.71896, 0.800519, 0.676851],\n",
       "  [0.087798, 0.095678, 0.059986, 0.079704, 0.065531]],\n",
       " 'E35-SHP': [[0.996233, 0.994366, 0.996234, 0.996233, 0.99435],\n",
       "  [0.563723, 0.611488, 0.525652, 0.678788, 0.597293],\n",
       "  [0.550603, 0.570011, 0.576321, 0.803945, 0.7082],\n",
       "  [0.074319, 0.082178, 0.076154, 0.051122, 0.084083]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"E48-SHP\n",
    "0.911634\n",
    "0.714322\n",
    "0.552646\n",
    "0.100274\n",
    "\n",
    "E48-SHP\n",
    "0.924783\n",
    "0.756357\n",
    "0.678377\n",
    "0.057948\n",
    "\n",
    "E48-SHP\n",
    "0.916744\n",
    "0.723712\n",
    "0.751705\n",
    "0.076777\n",
    "\n",
    "E48-SHP\n",
    "0.915334\n",
    "0.782168\n",
    "0.82064\n",
    "0.077664\n",
    "\n",
    "E48-SHP\n",
    "0.888455\n",
    "0.762912\n",
    "0.826717\n",
    "0.080682\n",
    "\n",
    "E47-SHP\n",
    "0.926393\n",
    "0.790332\n",
    "0.512468\n",
    "0.08803\n",
    "\n",
    "E47-SHP\n",
    "0.935305\n",
    "0.801184\n",
    "0.763281\n",
    "0.038964\n",
    "\n",
    "E47-SHP\n",
    "0.947202\n",
    "0.795011\n",
    "0.81812\n",
    "0.079581\n",
    "\n",
    "E47-SHP\n",
    "0.93199\n",
    "0.782948\n",
    "0.861406\n",
    "0.066335\n",
    "\n",
    "E47-SHP\n",
    "0.912968\n",
    "0.72203\n",
    "0.726697\n",
    "0.080838\n",
    "\n",
    "E46-SHP\n",
    "0.609361\n",
    "0.75557\n",
    "0.829323\n",
    "0.122514\n",
    "\n",
    "E46-SHP\n",
    "0.688224\n",
    "0.646946\n",
    "0.587759\n",
    "0.068016\n",
    "\n",
    "E46-SHP\n",
    "0.704962\n",
    "0.673611\n",
    "0.763867\n",
    "0.076611\n",
    "\n",
    "E46-SHP\n",
    "0.598473\n",
    "0.629381\n",
    "0.694606\n",
    "0.036437\n",
    "\n",
    "E46-SHP\n",
    "0.712253\n",
    "0.735236\n",
    "0.764935\n",
    "0.111215\n",
    "\n",
    "E45-SHP\n",
    "0.605599\n",
    "0.731953\n",
    "0.776975\n",
    "0.086086\n",
    "\n",
    "E45-SHP\n",
    "0.6777\n",
    "0.801716\n",
    "0.721015\n",
    "0.078189\n",
    "\n",
    "E45-SHP\n",
    "0.646318\n",
    "0.782887\n",
    "0.769809\n",
    "0.08505\n",
    "\n",
    "E45-SHP\n",
    "0.581926\n",
    "0.706306\n",
    "0.739891\n",
    "0.050539\n",
    "\n",
    "E45-SHP\n",
    "0.673149\n",
    "0.739048\n",
    "0.747892\n",
    "0.105751\n",
    "\n",
    "E44-SHP\n",
    "0.714243\n",
    "0.833282\n",
    "0.933392\n",
    "0.056083\n",
    "\n",
    "E44-SHP\n",
    "0.746843\n",
    "0.685071\n",
    "0.537353\n",
    "0.072866\n",
    "\n",
    "E44-SHP\n",
    "0.665712\n",
    "0.736512\n",
    "0.842934\n",
    "0.062078\n",
    "\n",
    "E44-SHP\n",
    "0.689275\n",
    "0.774483\n",
    "0.88213\n",
    "0.0672\n",
    "\n",
    "E44-SHP\n",
    "0.79202\n",
    "0.662222\n",
    "0.772932\n",
    "0.114144\n",
    "\n",
    "E43-SHP\n",
    "0.796979\n",
    "0.784924\n",
    "0.80317\n",
    "0.099218\n",
    "\n",
    "E43-SHP\n",
    "0.730684\n",
    "0.758952\n",
    "0.704489\n",
    "0.082034\n",
    "\n",
    "E43-SHP\n",
    "0.68999\n",
    "0.681042\n",
    "0.726528\n",
    "0.084849\n",
    "\n",
    "E43-SHP\n",
    "0.781944\n",
    "0.613127\n",
    "0.595106\n",
    "0.073327\n",
    "\n",
    "E43-SHP\n",
    "0.729565\n",
    "0.73328\n",
    "0.704466\n",
    "0.115084\n",
    "\n",
    "E42-SHP\n",
    "0.911634\n",
    "0.714322\n",
    "0.552646\n",
    "0.100274\n",
    "\n",
    "E42-SHP\n",
    "0.924783\n",
    "0.756357\n",
    "0.678377\n",
    "0.057948\n",
    "\n",
    "E42-SHP\n",
    "0.916744\n",
    "0.723712\n",
    "0.751705\n",
    "0.076777\n",
    "\n",
    "E42-SHP\n",
    "0.915334\n",
    "0.782168\n",
    "0.82064\n",
    "0.077664\n",
    "\n",
    "E42-SHP\n",
    "0.888455\n",
    "0.762912\n",
    "0.826717\n",
    "0.080682\n",
    "\n",
    "E41-SHP\n",
    "0.593661\n",
    "0.574505\n",
    "0.633967\n",
    "0.120356\n",
    "\n",
    "E41-SHP\n",
    "0.755893\n",
    "0.679759\n",
    "0.72005\n",
    "0.071099\n",
    "\n",
    "E41-SHP\n",
    "0.66464\n",
    "0.72415\n",
    "0.770474\n",
    "0.07496\n",
    "\n",
    "E41-SHP\n",
    "0.631355\n",
    "0.703409\n",
    "0.758989\n",
    "0.078137\n",
    "\n",
    "E41-SHP\n",
    "0.602499\n",
    "0.76411\n",
    "0.701181\n",
    "0.095788\n",
    "\n",
    "E40-SHP\n",
    "0.586194\n",
    "0.612219\n",
    "0.67942\n",
    "0.086265\n",
    "\n",
    "E40-SHP\n",
    "0.686391\n",
    "0.678793\n",
    "0.733373\n",
    "0.037829\n",
    "\n",
    "E40-SHP\n",
    "0.635703\n",
    "0.706593\n",
    "0.765801\n",
    "0.121043\n",
    "\n",
    "E40-SHP\n",
    "0.592576\n",
    "0.648599\n",
    "0.738637\n",
    "0.090218\n",
    "\n",
    "E40-SHP\n",
    "0.58641\n",
    "0.699692\n",
    "0.612774\n",
    "0.092392\n",
    "\n",
    "E39-SHP\n",
    "0.926393\n",
    "0.790332\n",
    "0.512468\n",
    "0.08803\n",
    "\n",
    "E39-SHP\n",
    "0.935305\n",
    "0.801184\n",
    "0.763281\n",
    "0.038964\n",
    "\n",
    "E39-SHP\n",
    "0.947202\n",
    "0.795011\n",
    "0.81812\n",
    "0.079581\n",
    "\n",
    "E39-SHP\n",
    "0.93199\n",
    "0.782948\n",
    "0.861406\n",
    "0.066335\n",
    "\n",
    "E39-SHP\n",
    "0.912968\n",
    "0.72203\n",
    "0.726697\n",
    "0.080838\n",
    "\n",
    "E38-SHP\n",
    "0.992482\n",
    "0.554426\n",
    "0.609996\n",
    "0.102797\n",
    "\n",
    "E38-SHP\n",
    "0.99435\n",
    "0.675867\n",
    "0.69221\n",
    "0.103424\n",
    "\n",
    "E38-SHP\n",
    "0.998117\n",
    "0.664008\n",
    "0.704597\n",
    "0.019946\n",
    "\n",
    "E38-SHP\n",
    "0.994349\n",
    "0.778436\n",
    "0.706883\n",
    "0.072356\n",
    "\n",
    "E38-SHP\n",
    "0.992466\n",
    "0.523756\n",
    "0.688129\n",
    "0.086632\n",
    "\n",
    "E37-SHP\n",
    "0.988745\n",
    "0.526579\n",
    "0.504826\n",
    "0.092013\n",
    "\n",
    "E37-SHP\n",
    "0.994365\n",
    "0.489267\n",
    "0.540975\n",
    "0.114545\n",
    "\n",
    "E37-SHP\n",
    "0.994366\n",
    "0.506091\n",
    "0.52436\n",
    "0.075384\n",
    "\n",
    "E37-SHP\n",
    "0.998117\n",
    "0.523942\n",
    "0.664761\n",
    "0.046922\n",
    "\n",
    "E37-SHP\n",
    "0.992466\n",
    "0.50006\n",
    "0.575982\n",
    "0.083993\n",
    "\n",
    "E36-SHP\n",
    "0.996234\n",
    "0.578681\n",
    "0.677627\n",
    "0.087798\n",
    "\n",
    "E36-SHP\n",
    "0.996233\n",
    "0.806794\n",
    "0.706332\n",
    "0.095678\n",
    "\n",
    "E36-SHP\n",
    "0.99435\n",
    "0.652738\n",
    "0.71896\n",
    "0.059986\n",
    "\n",
    "E36-SHP\n",
    "0.996233\n",
    "0.775874\n",
    "0.800519\n",
    "0.079704\n",
    "\n",
    "E36-SHP\n",
    "0.998117\n",
    "0.575105\n",
    "0.676851\n",
    "0.065531\n",
    "\n",
    "E35-SHP\n",
    "0.996233\n",
    "0.563723\n",
    "0.550603\n",
    "0.074319\n",
    "\n",
    "E35-SHP\n",
    "0.994366\n",
    "0.611488\n",
    "0.570011\n",
    "0.082178\n",
    "\n",
    "E35-SHP\n",
    "0.996234\n",
    "0.525652\n",
    "0.576321\n",
    "0.076154\n",
    "\n",
    "E35-SHP\n",
    "0.996233\n",
    "0.678788\n",
    "0.803945\n",
    "0.051122\n",
    "\n",
    "E35-SHP\n",
    "0.99435\n",
    "0.597293\n",
    "0.7082\n",
    "0.084083\n",
    "\"\"\"\n",
    "\n",
    "s = s.split(\"\\n\")\n",
    "\n",
    "results = {}\n",
    "offset = -1\n",
    "pred_t = 0\n",
    "for t in s:\n",
    "    if t == \"\":\n",
    "        continue\n",
    "    if t[0] == \"E\":\n",
    "        if t not in results:\n",
    "            results[t] = [list(), list(), list(), list()]\n",
    "        offset = -1\n",
    "        pred_t = t\n",
    "    else:\n",
    "        t = float(t)\n",
    "        offset += 1\n",
    "        results[pred_t][offset].append(t)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E35-SHP\n",
      "f1: 1.00 ± 0.00\n",
      "disentanglement: 0.60 ± 0.05\n",
      "completeness:0.64 ± 0.10\n",
      "informativeness: 0.07 ± 0.01\n",
      "\n",
      "E36-SHP\n",
      "f1: 1.00 ± 0.00\n",
      "disentanglement: 0.68 ± 0.10\n",
      "completeness:0.72 ± 0.05\n",
      "informativeness: 0.08 ± 0.01\n",
      "\n",
      "E37-SHP\n",
      "f1: 0.99 ± 0.00\n",
      "disentanglement: 0.51 ± 0.01\n",
      "completeness:0.56 ± 0.06\n",
      "informativeness: 0.08 ± 0.02\n",
      "\n",
      "E38-SHP\n",
      "f1: 0.99 ± 0.00\n",
      "disentanglement: 0.64 ± 0.09\n",
      "completeness:0.68 ± 0.04\n",
      "informativeness: 0.08 ± 0.03\n",
      "\n",
      "E39-SHP\n",
      "f1: 0.93 ± 0.01\n",
      "disentanglement: 0.78 ± 0.03\n",
      "completeness:0.74 ± 0.12\n",
      "informativeness: 0.07 ± 0.02\n",
      "\n",
      "E40-SHP\n",
      "f1: 0.62 ± 0.04\n",
      "disentanglement: 0.67 ± 0.03\n",
      "completeness:0.71 ± 0.05\n",
      "informativeness: 0.09 ± 0.03\n",
      "\n",
      "E41-SHP\n",
      "f1: 0.65 ± 0.06\n",
      "disentanglement: 0.69 ± 0.06\n",
      "completeness:0.72 ± 0.05\n",
      "informativeness: 0.09 ± 0.02\n",
      "\n",
      "E42-SHP\n",
      "f1: 0.91 ± 0.01\n",
      "disentanglement: 0.75 ± 0.03\n",
      "completeness:0.73 ± 0.10\n",
      "informativeness: 0.08 ± 0.01\n",
      "\n",
      "E43-SHP\n",
      "f1: 0.75 ± 0.04\n",
      "disentanglement: 0.71 ± 0.06\n",
      "completeness:0.71 ± 0.07\n",
      "informativeness: 0.09 ± 0.01\n",
      "\n",
      "E44-SHP\n",
      "f1: 0.72 ± 0.04\n",
      "disentanglement: 0.74 ± 0.06\n",
      "completeness:0.79 ± 0.14\n",
      "informativeness: 0.07 ± 0.02\n",
      "\n",
      "E45-SHP\n",
      "f1: 0.64 ± 0.04\n",
      "disentanglement: 0.75 ± 0.03\n",
      "completeness:0.75 ± 0.02\n",
      "informativeness: 0.08 ± 0.02\n",
      "\n",
      "E46-SHP\n",
      "f1: 0.66 ± 0.05\n",
      "disentanglement: 0.69 ± 0.05\n",
      "completeness:0.73 ± 0.08\n",
      "informativeness: 0.08 ± 0.03\n",
      "\n",
      "E47-SHP\n",
      "f1: 0.93 ± 0.01\n",
      "disentanglement: 0.78 ± 0.03\n",
      "completeness:0.74 ± 0.12\n",
      "informativeness: 0.07 ± 0.02\n",
      "\n",
      "E48-SHP\n",
      "f1: 0.91 ± 0.01\n",
      "disentanglement: 0.75 ± 0.03\n",
      "completeness:0.73 ± 0.10\n",
      "informativeness: 0.08 ± 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(35, 49):\n",
    "    exp = f\"E{i}-SHP\"\n",
    "    res = results[exp]\n",
    "    f1 = np.array(res[0])\n",
    "    D = np.array(res[1])\n",
    "    C = np.array(res[2])\n",
    "    I = np.array(res[3])\n",
    "    print(exp)\n",
    "    print(f\"f1: {f1.mean():.2f} ± {f1.std():.2f}\")\n",
    "    print(f\"disentanglement: {D.mean():.2f} ± {D.std():.2f}\")\n",
    "    print(f\"completeness:{C.mean():.2f} ± {C.std():.2f}\")\n",
    "    print(f\"informativeness: {I.mean():.2f} ± {I.std():.2f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bottleneck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
