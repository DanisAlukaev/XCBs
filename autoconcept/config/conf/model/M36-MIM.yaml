_target_: models.auto_concept_bottleneck.LitAutoConceptBottleneckModel

main:
  _target_: models.auto_concept_bottleneck.AutoConceptBottleneckModel

  feature_extractor:
    _target_: models.feature_extractors.torchvision.TorchvisionFeatureExtractor
    model: densenet121
    weights: IMAGENET1K_V1
    out_features: 20

  concept_extractor:
    _target_: models.concept_extractors.novel.ConceptExtractorAttention
    vocab_size: 8800
    embed_dim: 50
    out_features: 20
    max_len: 380
    src_pad_idx: 0
    dropout: 0.
    use_slot_norm: false
    norm_fn1:
      _target_: torch.nn.Softmax
      dim: -2
    norm_fn2:
      _target_: functional.operations.ScalerSum
      dim: -1
    regularize_distance: false
    use_position_encoding: true
    mlp_depth: 4
    use_dummy_concept: false
    use_dummy_tokens: false
    activation:
      _target_: torch.nn.ReLU
    device: cuda

  predictor:
    _target_: models.predictors.mlp.MLPPredictor
    layers: [20, 2]
    activation:
      _target_: torch.nn.ReLU

  interim_activation:
    _target_: torch.nn.Sigmoid

  predictor_aux:
    _target_: models.predictors.mlp.MLPPredictor
    layers: [20, 2]
    activation:
      _target_: torch.nn.ReLU

dist_weight: 0.0

criterion_task:
  _target_: torch.nn.CrossEntropyLoss

criterion_tie:
  _target_: functional.loss.JensenShannonDivergenceLoss
tie_weight: 0.0

mix_tie_epoch: null

pretrain_embeddings_epoch: null

tie_loss_wrt_concepts: true

optimizer_model_template:
  _target_: functools.partial
  _args_:
    - _target_: hydra.utils.get_class
      path: torch.optim.Adam
  lr: 0.001
  weight_decay: 1e-5
  amsgrad: true

optimizer_concept_extractor_template:
  _target_: functools.partial
  _args_:
    - _target_: hydra.utils.get_class
      path: torch.optim.AdamW
  lr: 2e-4
  weight_decay: 0.03

scheduler_model_template:
  _target_: functools.partial
  _args_:
    - _target_: hydra.utils.get_class
      path: torch.optim.lr_scheduler.MultiStepLR
  milestones: [2, 5]
  gamma: 0.1

scheduler_concept_extractor_template:
  _target_: functools.partial
  _args_:
    - _target_: hydra.utils.get_class
      path: torch.optim.lr_scheduler.MultiStepLR
  milestones: [3, 6]
  gamma: 0.3
